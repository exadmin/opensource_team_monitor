llm:
  provider: OPENAI

  meta:
    model: deepseek-chat
    max_tokens: 8096
    temperature: 0.2

prompt:
  normalize_prompts: true
  summary_prompt_files: [ ./prompts/summary.md ]

review:
  mode: ADDED_AND_REMOVED_WITH_CONTEXT
  inline_tag: "#ai-review:inline"
  inline_reply_tag: "#ai-review:inline-reply"
  summary_tag: "#ai-review:summary"
  summary_reply_tag: "#ai-review:summary-reply"
  context_lines: 50

vcs:
  provider: GITHUB

  http_client:
    timeout: 120
    api_url: https://api.github.com

