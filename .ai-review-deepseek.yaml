llm:
  provider: OPENAI

  meta:
    model: deepseek-chat
    max_tokens: 8096
    temperature: 0.2

prompt:
  normalize_prompts: false
  summary_prompt_files: [ ./prompts/summary.md ]

review:
  mode: ADDED_AND_REMOVED_WITH_CONTEXT
  inline_tag: "#deepseek-review:inline"
  inline_reply_tag: "#deepseek-review:inline-reply"
  summary_tag: "#deepseek-review:summary"
  summary_reply_tag: "#deepseek-review:summary-reply"
  context_lines: 25

logger:
  level: DEBUG
  format: "{time:YYYY-MM-DD HH:mm:ss} | {level} | {extra[logger_name]} | {message}"

vcs:
  provider: GITHUB

  http_client:
    timeout: 120
    api_url: https://api.github.com

