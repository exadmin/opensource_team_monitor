llm:
  provider: OLLAMA

  meta:
    model: mistral
    max_tokens: 2048
    temperature: 0.2

  http_client:
    timeout: 600
    api_url: http://localhost:11434

  prompt:
    normalize_prompts: true
  review:
    mode: ADDED_AND_REMOVED_WITH_CONTEXT
    inline_tag: "#ai-review:inline"
    inline_reply_tag: "#ai-review:inline-reply"
    summary_tag: "#ai-review:summary"
    summary_reply_tag: "#ai-review:summary-reply"
    context_lines: 50

vcs:
  provider: GITHUB

  http_client:
    timeout: 120
    api_url: https://api.github.com
